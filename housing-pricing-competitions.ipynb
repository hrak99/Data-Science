{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introduction\nMachine learning competitions are a great way to improve your data science skills and measure your progress. \n\nIn this competition, we will predict housing prices on the basis of available data, data cleansing, feature engineeing and metrics.\n\n"},{"metadata":{},"cell_type":"markdown","source":"## Libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# Code you have previously used to load data\nimport time\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestRegressor\n#from sklearn.pipeline import make_pipeline\n#from sklearn.ensemble import RandomForestClassifier\n#from sklearn.model_selection import cross_val_score\n#from xgboost import XGBRegressor\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.ensemble import GradientBoostingRegressor\n#from sklearn.impute import SimpleImputer\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import train_test_split\n#from sklearn.tree import DecisionTreeRegressor\nfrom learntools.core import *\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\npd.set_option('display.width', None)\n# import warnings filter\nfrom warnings import simplefilter\n# ignore all future warnings\nsimplefilter(action='ignore', category=FutureWarning)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#iowa_file_path = '../input/train.csv'\n\n#home_data = pd.read_csv(iowa_file_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#home_data=home_data.rename(columns={'1stFlrSF':'FirstFlrSF', '2ndFlrSF' : 'SecondFlrSF'} )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#pandas doesn't show us all the decimals\n#pd.options.display.precision = 15","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#home_data._get_numeric_data().head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reading the file\n\niowa_file_path = '../input/train.csv'\n\nhome_data = pd.read_csv(iowa_file_path)\n\n# Renaming the columns\n\nhome_data=home_data.rename(columns={'1stFlrSF':'FirstFlrSF', '2ndFlrSF' : 'SecondFlrSF'} )\n\n# Filling the NAN values according to set metric , The Mean Absolute Error\n\nhome_data['MasVnrType'].unique()\nhome_data['MasVnrType']=home_data['MasVnrType'].fillna('BrkCmn')\nhome_data['MasVnrType']=home_data['MasVnrType'].fillna('BrkCmn')\nhome_data['MasVnrArea']=home_data['MasVnrArea'].fillna(0)\nhome_data['MiscFeature'].unique()\nhome_data['MiscFeature']=home_data['MiscFeature'].fillna('TenC')\nhome_data['Fence'].unique()\nhome_data['Fence']=home_data['Fence'].fillna('MnWw')\nhome_data['LotFrontage'].describe()\nhome_data['LotFrontage']=home_data['LotFrontage'].fillna(70)\nhome_data['PoolQC'].unique()\nhome_data['PoolQC']=home_data['PoolQC'].fillna('Gd')\nhome_data['GarageCond'].unique()\nhome_data['GarageCond']=home_data['GarageCond'].fillna('Ex')\nhome_data['GarageQual'].unique()\nhome_data['GarageQual']=home_data['GarageQual'].fillna('Po')\nhome_data['GarageFinish'].unique()\nhome_data['GarageFinish']=home_data['GarageFinish'].fillna('Fin')\nhome_data['GarageYrBlt'].describe()\nhome_data['GarageYrBlt']=home_data['GarageYrBlt'].fillna(1978)\nhome_data['GarageType'].unique()\nhome_data['GarageType']=home_data['GarageType'].fillna('2Types')\nhome_data['FireplaceQu'].unique()\nhome_data['FireplaceQu']=home_data['FireplaceQu'].fillna('Po')\nhome_data['Electrical'].unique()\nhome_data['Electrical']=home_data['Electrical'].fillna('FuseA')\nhome_data['BsmtFinType2'].unique()\nhome_data['BsmtFinType2']=home_data['BsmtFinType2'].fillna('BLQ')\nhome_data['BsmtFinType1'].unique()\nhome_data['BsmtFinType1']=home_data['BsmtFinType1'].fillna('LwQ')\nhome_data['BsmtExposure'].unique() \nhome_data['BsmtExposure']=home_data['BsmtExposure'].fillna('Av')\nhome_data['BsmtCond'].unique()\nhome_data['BsmtCond']=home_data['BsmtCond'].fillna('Po')\nhome_data['Alley'].unique()\nhome_data['Alley']= home_data['Alley'].fillna('Pave')\nhome_data['BsmtQual'].unique()\nhome_data['BsmtQual']=home_data['BsmtQual'].fillna('Fa')\n\n\n# Label Encoding (Transforming non-categorical values into tabular form)\n\nfrom sklearn.preprocessing import LabelEncoder\n\nfor f in ['MSZoning','Street', 'Alley', 'LotShape','LandContour','Utilities','LotConfig','LandSlope',\\\n          'Neighborhood','Condition1','Condition2','BldgType','HouseStyle',\\\n         'RoofStyle','RoofMatl','Exterior1st','Exterior2nd','MasVnrType','ExterQual','ExterCond',\\\n          'Foundation','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2',\\\n         'Heating','HeatingQC','CentralAir','Electrical','KitchenQual','Functional',\\\n          'FireplaceQu','GarageType','GarageFinish','GarageQual','GarageCond','PavedDrive',\\\n         'PoolQC','Fence','MiscFeature','SaleType','SaleCondition']:\n    lbl = LabelEncoder()\n    lbl.fit(list(home_data[f].values) + list(home_data[f].values))\n    home_data[f] = lbl.transform(list(home_data[f].values))\n    #test_data[f] = lbl.transform(list(test_data[f].values))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Anomaly Detection"},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nvar = home_data['LotArea']\nf, ax = plt.subplots(figsize=(13,8))\nsns.scatterplot(y=home_data.SalePrice, x=var)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"home_data['LotArea'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"home_data.LotArea[home_data.LotArea >= 200000]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Give some values to the data which is showing an anomaly\n\nhome_data.LotArea[home_data.LotArea >= 200000] =  11601.500000000000000\nhome_data.LotArea[home_data.LotArea >= 160000] = 45600.38\n#home_data.MiscVal[home_data.MiscVal>= 70_000] = 250000\n#home_data.LotArea[home_data.LotArea >= 150000] = 59600\n#home_data.LotArea[home_data.LotArea >= 110000] = 60800\n#home_data.LotFrontage[home_data.LotFrontage >= 300] =195\n#home_data.MasVnrArea[home_data.MasVnrArea >= 1000] =500.25\n#home_data.BsmtFinSF1[home_data.BsmtFinSF1 >= 5000] = 2200\n#home_data.BsmtFinSF2[home_data.BsmtFinSF2 >= 1400] = 1150.32\n#home_data.TotalBsmtSF[home_data.TotalBsmtSF >= 6000] = 2750.32","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#home_data.loc[home_data['MiscVal'] >=4000]\n#home_data['LotArea'].describe()\n#home_data.Neighborhood[home_data.Neighborhood>= 70_000] = 250000","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#home_data = home_data.drop([1230], axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#home_data['MiscVal'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#home_data.MiscVal[home_data.MiscVal >= 4_000] = 1000","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Engineering"},{"metadata":{},"cell_type":"markdown","source":"## Feature Engineering is based on correlation and creating new feature if required. We will do on the basis of correlation\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"### View of Correlation Matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ncorr_matrix=home_data._get_numeric_data().corr()\nfig, ax = plt.subplots(figsize=(30,20))         # Sample figsize in inches\nsns.heatmap(corr_matrix, annot=False, linewidths=5, ax=ax, xticklabels=corr_matrix.columns.values,yticklabels=corr_matrix.columns.values)\n#sns.heatmap(corr, annot=True, fmt=\".1f\",linewidth=0.5 xticklabels=corr.columns.values,yticklabels=corr.columns.values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"home_data._get_numeric_data().corr()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## It is impossible to see correlation from above techniques. So we find each aganist thr target variable through importing stats"},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy import stats\n\n#1\npearson_coef, p_value = stats.pearsonr(home_data['MSZoning'], home_data['SalePrice'])\nprint(\"#1 The Pearson Correlation Coefficient 'MSZoning' is\", pearson_coef, \" with a P-value of P =\", p_value)\n\n#2\npearson_coef, p_value = stats.pearsonr(home_data['Street'], home_data['SalePrice'])\nprint(\"#2 The Pearson Correlation Coefficient Street is\", pearson_coef, \" with a P-value of P =\", p_value)\n\n#3\npearson_coef, p_value = stats.pearsonr(home_data['Alley'], home_data['SalePrice'])\nprint(\"#3 The Pearson Correlation Coefficient 'Alley' is\", pearson_coef, \" with a P-value of P =\", p_value)\n\n#4\npearson_coef, p_value = stats.pearsonr(home_data['LotShape'], home_data['SalePrice'])\nprint(\"#4 The Pearson Correlation Coefficient 'LotShape' is\", pearson_coef, \" with a P-value of P =\", p_value)\n\n#5\npearson_coef, p_value = stats.pearsonr(home_data['LandContour'], home_data['SalePrice'])\nprint(\"#5 The Pearson Correlation Coefficient 'LandContour is\", pearson_coef, \" with a P-value of P =\", p_value)\n\n#6\npearson_coef, p_value = stats.pearsonr(home_data['Utilities'], home_data['SalePrice'])\nprint(\"#6 The Pearson Correlation Coefficient 'Utilities' is\", pearson_coef, \" with a P-value of P =\", p_value)\n\n#7\npearson_coef, p_value = stats.pearsonr(home_data['LotConfig'], home_data['SalePrice'])\nprint(\"#7 The Pearson Correlation Coefficient 'LotConfig' is\", pearson_coef, \" with a P-value of P =\", p_value)\n\n#8\npearson_coef, p_value = stats.pearsonr(home_data['LandSlope'], home_data['SalePrice'])\nprint(\"#8 The Pearson Correlation Coefficient 'LandSlope' is\", pearson_coef, \" with a P-value of P =\", p_value)\n\n#9\npearson_coef, p_value = stats.pearsonr(home_data['Neighborhood'], home_data['SalePrice'])\nprint(\"#9 The Pearson Correlation Coefficient 'Neighborhood' is\", pearson_coef, \" with a P-value of P =\", p_value)\n\n#10\npearson_coef, p_value = stats.pearsonr(home_data['Condition1'], home_data['SalePrice'])\nprint(\"#10 The Pearson Correlation Coefficient 'Condition1' is\", pearson_coef, \" with a P-value of P =\", p_value)\n\n#11\npearson_coef, p_value = stats.pearsonr(home_data['Condition2'], home_data['SalePrice'])\nprint(\"#11 The Pearson Correlation Coefficient'Condition2' is\", pearson_coef, \" with a P-value of P =\", p_value)\n\n#12\npearson_coef, p_value = stats.pearsonr(home_data['BldgType'], home_data['SalePrice'])\nprint(\"#12 The Pearson Correlation Coefficient 'BldgType' is\", pearson_coef, \" with a P-value of P =\", p_value)\n\n#13\npearson_coef, p_value = stats.pearsonr(home_data['HouseStyle'], home_data['SalePrice'])\nprint(\"#13 The Pearson Correlation Coefficient 'HouseStyle' is\", pearson_coef, \" with a P-value of P =\", p_value)\n\n#14\npearson_coef, p_value = stats.pearsonr(home_data['RoofStyle'], home_data['SalePrice'])\nprint(\"#14 The Pearson Correlation Coefficient 'RoofStyle' is\", pearson_coef, \" with a P-value of P =\", p_value)\n\n#15\npearson_coef, p_value = stats.pearsonr(home_data['RoofMatl'], home_data['SalePrice'])\nprint(\"#15 The Pearson Correlation Coefficient 'RoofMatl' is\", pearson_coef, \" with a P-value of P =\", p_value)\n\n#16\npearson_coef, p_value = stats.pearsonr(home_data['Exterior1st'], home_data['SalePrice'])\nprint(\"#16 The Pearson Correlation Coefficient 'Exterior1st' is\", pearson_coef, \" with a P-value of P =\", p_value)\n            \n                                                 \n#17\npearson_coef, p_value = stats.pearsonr(home_data['Exterior2nd'], home_data['SalePrice'])\nprint(\"#17 The Pearson Correlation Coefficient 'Exterior2nd'is\", pearson_coef, \" with a P-value of P =\", p_value)\n\n#18\npearson_coef, p_value = stats.pearsonr(home_data['MasVnrType'], home_data['SalePrice'])\nprint(\"#18 The Pearson Correlation Coefficient 'MasVnrType' is\", pearson_coef, \" with a P-value of P =\", p_value)\n\n#19\npearson_coef, p_value = stats.pearsonr(home_data['ExterQual'], home_data['SalePrice'])\nprint(\"#19 The Pearson Correlation Coefficient'ExterQual' is\", pearson_coef, \" with a P-value of P =\", p_value)\n\n#20\npearson_coef, p_value = stats.pearsonr(home_data['ExterCond'], home_data['SalePrice'])\nprint(\"#20 The Pearson Correlation Coefficient 'ExterCond' is\", pearson_coef, \" with a P-value of P =\", p_value)\n\n#21\npearson_coef, p_value = stats.pearsonr(home_data[ 'Foundation'], home_data['SalePrice'])\nprint(\"#21 The Pearson Correlation Coefficient  'Foundation' is\", pearson_coef, \" with a P-value of P =\", p_value)\n\n#22\npearson_coef, p_value = stats.pearsonr(home_data['BsmtQual'], home_data['SalePrice'])\nprint(\"#22 The Pearson Correlation Coefficient 'BsmtQual' is\", pearson_coef, \" with a P-value of P =\", p_value)\n\n#23\npearson_coef, p_value = stats.pearsonr(home_data['BsmtCond'], home_data['SalePrice'])\nprint(\"#23 The Pearson Correlation Coefficient 'Alley' is\", pearson_coef, \" with a P-value of P =\", p_value)\n\n#24\npearson_coef, p_value = stats.pearsonr(home_data['BsmtExposure'], home_data['SalePrice'])\nprint(\"#24 The Pearson Correlation Coefficient 'BsmtExposure' is\", pearson_coef, \" with a P-value of P =\", p_value)\n\n#25\npearson_coef, p_value = stats.pearsonr(home_data['BsmtFinType1'], home_data['SalePrice'])\nprint(\"#25 The Pearson Correlation Coefficient 'BsmtFinType1' is\", pearson_coef, \" with a P-value of P =\", p_value)\n\n#26\npearson_coef, p_value = stats.pearsonr(home_data['BsmtFinType2'], home_data['SalePrice'])\nprint(\"#26 The Pearson Correlation Coefficient 'BsmtFinType2' is\", pearson_coef, \" with a P-value of P =\", p_value)\n\n#27\npearson_coef, p_value = stats.pearsonr(home_data['Heating'], home_data['SalePrice'])\nprint(\"#27 The Pearson Correlation Coefficient 'Heating' is\", pearson_coef, \" with a P-value of P =\", p_value)\n\n#28\npearson_coef, p_value = stats.pearsonr(home_data['HeatingQC'], home_data['SalePrice'])\nprint(\"#28 The Pearson Correlation Coefficient 'HeatingQC' is\", pearson_coef, \" with a P-value of P =\", p_value)\n\n#29\npearson_coef, p_value = stats.pearsonr(home_data['CentralAir'], home_data['SalePrice'])\nprint(\"#29 The Pearson Correlation Coefficient 'CentralAir' is\", pearson_coef, \" with a P-value of P =\", p_value)\n\n#30\npearson_coef, p_value = stats.pearsonr(home_data['Electrical'], home_data['SalePrice'])\nprint(\"#30 The Pearson Correlation Coefficient 'Electrical' is\", pearson_coef, \" with a P-value of P =\", p_value)\n\n#31\npearson_coef, p_value = stats.pearsonr(home_data['KitchenQual'], home_data['SalePrice'])\nprint(\"#31 The Pearson Correlation Coefficient 'KitchenQual is\", pearson_coef, \" with a P-value of P =\", p_value)\n\n#32\npearson_coef, p_value = stats.pearsonr(home_data['Functional'], home_data['SalePrice'])\nprint(\"#32 The Pearson Correlation Coefficient 'Functional' is\", pearson_coef, \" with a P-value of P =\", p_value)\n\n#33\npearson_coef, p_value = stats.pearsonr(home_data['FireplaceQu'], home_data['SalePrice'])\nprint(\"#33 The Pearson Correlation Coefficient 'FireplaceQu' is\", pearson_coef, \" with a P-value of P =\", p_value)\n\n#34\npearson_coef, p_value = stats.pearsonr(home_data['GarageType'], home_data['SalePrice'])\nprint(\"#34 The Pearson Correlation Coefficient 'GarageType' is\", pearson_coef, \" with a P-value of P =\", p_value)\n\n#35\npearson_coef, p_value = stats.pearsonr(home_data['GarageFinish'], home_data['SalePrice'])\nprint(\"#35 The Pearson Correlation Coefficient 'GarageFinish' is\", pearson_coef, \" with a P-value of P =\", p_value)\n\n#36\npearson_coef, p_value = stats.pearsonr(home_data['GarageQual'], home_data['SalePrice'])\nprint(\"#36 The Pearson Correlation Coefficient 'GarageQual' is\", pearson_coef, \" with a P-value of P =\", p_value)\n                                            \n#37\npearson_coef, p_value = stats.pearsonr(home_data['GarageCond'], home_data['SalePrice'])\nprint(\"#37 The Pearson Correlation Coefficient 'GarageCond'is\", pearson_coef, \" with a P-value of P =\", p_value)\n\n#38\npearson_coef, p_value = stats.pearsonr(home_data['PavedDrive'], home_data['SalePrice'])\nprint(\"#38 The Pearson Correlation Coefficient 'PavedDrive' is\", pearson_coef, \" with a P-value of P =\", p_value)\n\n#39\npearson_coef, p_value = stats.pearsonr(home_data[ 'PoolQC'], home_data['SalePrice'])\nprint(\"#39 The Pearson Correlation Coefficient'PoolQC' is\", pearson_coef, \" with a P-value of P =\", p_value)\n\n#40\npearson_coef, p_value = stats.pearsonr(home_data['Fence'], home_data['SalePrice'])\nprint(\"#40 The Pearson Correlation Coefficient 'Fence' is\", pearson_coef, \" with a P-value of P =\", p_value)\n\n#41\npearson_coef, p_value = stats.pearsonr(home_data['MiscFeature'], home_data['SalePrice'])\nprint(\"#41 The Pearson Correlation Coefficient 'MiscFeature' is\", pearson_coef, \" with a P-value of P =\", p_value)\n\n#42\npearson_coef, p_value = stats.pearsonr(home_data['SaleType'], home_data['SalePrice'])\nprint(\"#42 The Pearson Correlation Coefficient 'SaleType' is\", pearson_coef, \" with a P-value of P =\", p_value)\n\n#43\npearson_coef, p_value = stats.pearsonr(home_data['SaleCondition'], home_data['SalePrice'])\nprint(\"#43 The Pearson Correlation Coefficient'SaleCondition' is\", pearson_coef, \" with a P-value of P =\", p_value)\n\nfrom scipy import stats\n#1\npearson_coef, p_value = stats.pearsonr(home_data['MSSubClass'], home_data['SalePrice'])\nprint(\"#1 The Pearson Correlation Coefficient MSSubClass is\", pearson_coef, \" with a P-value of P =\", p_value)\n\n#1\npearson_coef, p_value = stats.pearsonr(home_data['LotFrontage'], home_data['SalePrice'])\nprint(\"#1 The Pearson Correlation Coefficient LotFrontage is\", pearson_coef, \" with a P-value of P =\", p_value)\n\n#1\npearson_coef, p_value = stats.pearsonr(home_data['LotArea'], home_data['SalePrice'])\nprint(\"#1 The Pearson Correlation Coefficient LotArea is\", pearson_coef, \" with a P-value of P =\", p_value)\n\n#1\npearson_coef, p_value = stats.pearsonr(home_data['OverallQual'], home_data['SalePrice'])\nprint(\"#1 The Pearson Correlation Coefficient OverallQual is\", pearson_coef, \" with a P-value of P =\", p_value)\n\n#1\npearson_coef, p_value = stats.pearsonr(home_data['OverallCond'], home_data['SalePrice'])\nprint(\"#1 The Pearson Correlation Coefficient OverallCond is\", pearson_coef, \" with a P-value of P =\", p_value)\n\n#1 \npearson_coef, p_value = stats.pearsonr(home_data['YearBuilt'], home_data['SalePrice'])\nprint(\"#1 The Pearson Correlation Coefficient YearBuilt is\", pearson_coef, \" with a P-value of P =\", p_value)\n\n#1\npearson_coef, p_value = stats.pearsonr(home_data['YearRemodAdd'], home_data['SalePrice'])\nprint(\"#1 The Pearson Correlation Coefficient YearRemodAdd is\", pearson_coef, \" with a P-value of P =\", p_value)\n\n#1\npearson_coef, p_value = stats.pearsonr(home_data['MasVnrArea'], home_data['SalePrice'])\nprint(\"#1 The Pearson Correlation Coefficient MasVnrArea is\", pearson_coef, \" with a P-value of P =\", p_value)\n\n#1\npearson_coef, p_value = stats.pearsonr(home_data['BsmtFinSF1'], home_data['SalePrice'])\nprint(\"#1 The Pearson Correlation Coefficient BsmtFinSF1 is\", pearson_coef, \" with a P-value of P =\", p_value)\n\n#1\npearson_coef, p_value = stats.pearsonr(home_data['BsmtFinSF2'], home_data['SalePrice'])\nprint(\"#1 The Pearson Correlation Coefficient BsmtFinSF2 is\", pearson_coef, \" with a P-value of P =\", p_value)\n\n\n#1\npearson_coef, p_value = stats.pearsonr(home_data['EnclosedPorch'], home_data['SalePrice'])\nprint(\"#1 The Pearson Correlation Coefficient EnclosedPorch is\", pearson_coef, \" with a P-value of P =\", p_value)\n\n#1\npearson_coef, p_value = stats.pearsonr(home_data['3SsnPorch'], home_data['SalePrice'])\nprint(\"#1 The Pearson Correlation Coefficient BedroomAbvGr is\", pearson_coef, \" with a P-value of P =\", p_value)\n\n#1\npearson_coef, p_value = stats.pearsonr(home_data['ScreenPorch'], home_data['SalePrice'])\nprint(\"#1 The Pearson Correlation Coefficient ScreenPorch is\", pearson_coef, \" with a P-value of P =\", p_value)\n\n#1\npearson_coef, p_value = stats.pearsonr(home_data['PoolArea'], home_data['SalePrice'])\nprint(\"#1 The Pearson Correlation Coefficient PoolArea is\", pearson_coef, \" with a P-value of P =\", p_value)\n\n#1\npearson_coef, p_value = stats.pearsonr(home_data['MiscVal'], home_data['SalePrice'])\nprint(\"#1 The Pearson Correlation Coefficient MiscVal is\", pearson_coef, \" with a P-value of P =\", p_value)\n\n#1\npearson_coef, p_value = stats.pearsonr(home_data['MoSold'], home_data['SalePrice'])\nprint(\"#1 The Pearson Correlation Coefficient MoSold is\", pearson_coef, \" with a P-value of P =\", p_value)\n\n#1\npearson_coef, p_value = stats.pearsonr(home_data['YrSold'], home_data['SalePrice'])\nprint(\"#1 The Pearson Correlation Coefficient YrSold is\", pearson_coef, \" with a P-value of P =\", p_value)\n\n#1\npearson_coef, p_value = stats.pearsonr(home_data['HalfBath'], home_data['SalePrice'])\nprint(\"#1 The Pearson Correlation Coefficient HalfBath is\", pearson_coef, \" with a P-value of P =\", p_value)\n\n#1\npearson_coef, p_value = stats.pearsonr(home_data['BedroomAbvGr'], home_data['SalePrice'])\nprint(\"#1 The Pearson Correlation Coefficient BedroomAbvGr is\", pearson_coef, \" with a P-value of P =\", p_value)\n\n#1\npearson_coef, p_value = stats.pearsonr(home_data['KitchenAbvGr'], home_data['SalePrice'])\nprint(\"#1 The Pearson Correlation Coefficient KitchenAbvGr is\", pearson_coef, \" with a P-value of P =\", p_value)\n\n#1\npearson_coef, p_value = stats.pearsonr(home_data['TotRmsAbvGrd'], home_data['SalePrice'])\nprint(\"#1 The Pearson Correlation Coefficient TotRmsAbvGrd is\", pearson_coef, \" with a P-value of P =\", p_value)\n\n#1\npearson_coef, p_value = stats.pearsonr(home_data['Fireplaces'], home_data['SalePrice'])\nprint(\"#1 The Pearson Correlation Coefficient Fireplaces is\", pearson_coef, \" with a P-value of P =\", p_value)\n\n#1\npearson_coef, p_value = stats.pearsonr(home_data['GarageYrBlt'], home_data['SalePrice'])\nprint(\"#1 The Pearson Correlation Coefficient GarageYrBlt is\", pearson_coef, \" with a P-value of P =\", p_value)\n\n#1\npearson_coef, p_value = stats.pearsonr(home_data['GarageCars'], home_data['SalePrice'])\nprint(\"#1 The Pearson Correlation Coefficient GarageCars is\", pearson_coef, \" with a P-value of P =\", p_value)\n\n#1\npearson_coef, p_value = stats.pearsonr(home_data['GarageArea'], home_data['SalePrice'])\nprint(\"#1 The Pearson Correlation Coefficient GarageArea is\", pearson_coef, \" with a P-value of P =\", p_value)\n\n#1\npearson_coef, p_value = stats.pearsonr(home_data['WoodDeckSF'], home_data['SalePrice'])\nprint(\"#1 The Pearson Correlation Coefficient WoodDeckSF is\", pearson_coef, \" with a P-value of P =\", p_value)\n\n#1\npearson_coef, p_value = stats.pearsonr(home_data['OpenPorchSF'], home_data['SalePrice'])\nprint(\"#1 The Pearson Correlation Coefficient OpenPorchSF is\", pearson_coef, \" with a P-value of P =\", p_value)\n\n#1\npearson_coef, p_value = stats.pearsonr(home_data['BsmtUnfSF'], home_data['SalePrice'])\nprint(\"#1 The Pearson Correlation Coefficient BsmtUnfSF is\", pearson_coef, \" with a P-value of P =\", p_value)\n\n#1\npearson_coef, p_value = stats.pearsonr(home_data['BsmtFinSF2'], home_data['SalePrice'])\nprint(\"#1 The Pearson Correlation Coefficient BsmtFinSF2 is\", pearson_coef, \" with a P-value of P =\", p_value)\n\n#1\npearson_coef, p_value = stats.pearsonr(home_data['TotalBsmtSF'], home_data['SalePrice'])\nprint(\"#1 The Pearson Correlation Coefficient TotalBsmtSF is\", pearson_coef, \" with a P-value of P =\", p_value)\n\n#1\npearson_coef, p_value = stats.pearsonr(home_data['FirstFlrSF'], home_data['SalePrice'])\nprint(\"#1 The Pearson Correlation Coefficient 1stFlrSF is\", pearson_coef, \" with a P-value of P =\", p_value)\n\n#1\npearson_coef, p_value = stats.pearsonr(home_data['SecondFlrSF'], home_data['SalePrice'])\nprint(\"#1 The Pearson Correlation Coefficient 2ndFlrSF is\", pearson_coef, \" with a P-value of P =\", p_value)\n\n#1\npearson_coef, p_value = stats.pearsonr(home_data['LowQualFinSF'], home_data['SalePrice'])\nprint(\"#1 The Pearson Correlation Coefficient LowQualFinSF is\", pearson_coef, \" with a P-value of P =\", p_value)\n\n#1\npearson_coef, p_value = stats.pearsonr(home_data['GrLivArea'], home_data['SalePrice'])\nprint(\"#1 The Pearson Correlation Coefficient GrLivArea is\", pearson_coef, \" with a P-value of P =\", p_value)\n\n#1\npearson_coef, p_value = stats.pearsonr(home_data['BsmtFullBath'], home_data['SalePrice'])\nprint(\"#1 The Pearson Correlation Coefficient BsmtFullBath is\", pearson_coef, \" with a P-value of P =\", p_value)\n\n#1\npearson_coef, p_value = stats.pearsonr(home_data['BsmtHalfBath'], home_data['SalePrice'])\nprint(\"#1 The Pearson Correlation Coefficient BsmtHalfBath is\", pearson_coef, \" with a P-value of P =\", p_value)\n\n#1\npearson_coef, p_value = stats.pearsonr(home_data['FullBath'], home_data['SalePrice'])\nprint(\"#1 The Pearson Correlation Coefficient FullBath is\", pearson_coef, \" with a P-value of P =\", p_value)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Designing & Evaluation"},{"metadata":{},"cell_type":"markdown","source":"## Now we have selected variables on the basis of correlation and the target variable.\n\n## We will split the dataset into train-test datasets to improve our model. Though we will run separately the test set but this is the best way to look inside.\n\n## Then we will tune every possible parameter of Gradient Boosting Regressor to improve the model.\n\n## For tuning, we will select a metirc like Mean Absoulte Error for verification. In this metric, the lowerst score would be the ideal one."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Selected Features\n\nX=home_data[['MSZoning','Street', 'Alley', 'LotShape','LandContour','Utilities','LandSlope',\\\n          'Condition1','Condition2','BldgType','HouseStyle','LotConfig', 'Neighborhood',\\\n         'RoofStyle','RoofMatl','Exterior1st','Exterior2nd','ExterQual','ExterCond',\\\n          'BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2',\\\n         'Heating','HeatingQC','CentralAir','Electrical','KitchenQual','Functional',\\\n          'GarageType','GarageFinish','GarageQual','GarageCond','PavedDrive',\\\n         'PoolQC','Fence','MiscFeature','SaleType','SaleCondition','LotFrontage',\\\n             'BsmtFinSF2','BsmtFinSF1','LotArea', 'OverallQual','OverallCond','YearBuilt','YearRemodAdd','MasVnrArea',\\\n            'BsmtUnfSF','TotalBsmtSF','FirstFlrSF','SecondFlrSF','LowQualFinSF',\\\n             'BsmtFullBath','GrLivArea','BsmtHalfBath','FullBath','HalfBath','BedroomAbvGr',\\\n             'KitchenAbvGr','TotRmsAbvGrd','Fireplaces','GarageYrBlt','GarageCars','GarageArea',\\\n             'WoodDeckSF','OpenPorchSF','3SsnPorch','EnclosedPorch','ScreenPorch','PoolArea',\\\n             'MiscVal','MoSold','YrSold',\n           ]]\n\n# Target Variable\n\ny=home_data.SalePrice\n\n# Split into validation and training data\n\ntrain_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\n\n# Specify Model\n#iowa_model = RandomForestRegressor(random_state=0,n_estimators=110,max_depth=None,max_leaf_nodes=324,\n#                                              n_jobs=-1,min_samples_leaf=1) #110,325\n                                           \n#iowa_model = XGBRegressor(random_state=1,max_depth=6,max_leaf_nodes=None\n                         # , learning_rate=0.3,n_estimators=500,n_jobs=4,objective=\"reg:linear\")\n                                       \n\n# Rough Model to Start With       \n\niowa_model = GradientBoostingRegressor(random_state=0,max_depth=3,max_leaf_nodes=None,n_estimators=100,\n                                       learning_rate=0.08,min_samples_leaf=1,\n                                       )\n                                           \n# Fit Model\n\niowa_model.fit(train_X, train_y)\n\n# Make validation predictions and calculate mean absolute error\n\nval_predictions = iowa_model.predict(val_X)\nval_mae = mean_absolute_error(val_predictions, val_y)\nprint(\"Validation MAE when not specifying max_leaf_nodes: {:,.0f}\".format(val_mae))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## Tuning Parameters"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### max_leaf_nodes"},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y):\n    model = GradientBoostingRegressor(max_leaf_nodes=max_leaf_nodes,random_state=1,max_depth=3,\n                                      learning_rate=0.08)\n                                     # n_estimators=110, random_state=1,n_jobs=-1)\n    model.fit(train_X, train_y)\n    preds_val = model.predict(val_X)\n    mae = mean_absolute_error(val_y,preds_val)\n    return(mae)\n\ncandidate_max_leaf_nodes = [5, 25, 50,75, 100,125,150,175,200,225,250,275,300,325,350,375,400,425,450,475,500,600,700,800,900,1000]#[5, 25, 50,75, 100,125,150,175,200, 250, 500]\n# Write loop to find the ideal tree size from candidate_max_leaf_nodes\nfor max_leaf_nodes in candidate_max_leaf_nodes:\n    my_mae = get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y)\n    print(\"Max leaf nodes: %d  \\t\\t Mean Absolute Error:  %d\" %(max_leaf_nodes, my_mae))\n\n#rf_model_on_full_data = RandomForestRegressor(random_state=1,max_leaf_nodes=100,n_estimators=150)\n                                             # n_jobs=-1)\n\n# fit rf_model_on_full_data on all data from the training data\n#rf_model_on_full_data.fit(X,y)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### n_estimators"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_mae(n_estimators, train_X, val_X, train_y, val_y):\n    model = GradientBoostingRegressor(n_estimators=n_estimators,random_state=0,max_depth=3,\n                                      max_leaf_nodes=5,learning_rate=0.08) \n    model.fit(train_X, train_y)\n    preds_val = model.predict(val_X)\n    mae = mean_absolute_error(val_y, preds_val)\n    return(mae)\n\nfind_n_estimators = [5,25,50,75,100,105,110,115,120,125,130,135,140,145,150,155,160,165,170,\\\n                     175,180,185,190,195,200,205,210,215,220,225,230,235,240,245,250]\n# Write loop to find the ideal tree size from candidate_max_leaf_nodes\nfor n_estimators in find_n_estimators:\n    my_mae = get_mae(n_estimators, train_X, val_X, train_y, val_y)\n    print(\"n_estimators: %d  \\t\\t Mean Absolute Error:  %d\" %(n_estimators, my_mae))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_mae(n_estimators, train_X, val_X, train_y, val_y):\n    model = GradientBoostingRegressor(n_estimators=n_estimators,random_state=0,max_depth=3,max_leaf_nodes=5,\\\n                                      learning_rate=0.08) \n    model.fit(train_X, train_y)\n    preds_val = model.predict(val_X)\n    mae = mean_absolute_error(val_y, preds_val)\n    return(mae)\n\nfind_n_estimators = [250,260,270,280,290,300,310,320,330,340,350,360,370,380,390,400,410,420,430,440,450,\n                     460,470,480,490,500,510,520,530,645,650,655,660,665,670,675,680,685,690,695,700]\n# Write loop to find the ideal tree size from candidate_max_leaf_nodes\nfor n_estimators in find_n_estimators:\n    my_mae = get_mae(n_estimators, train_X, val_X, train_y, val_y)\n    print(\"n_estimators: %d  \\t\\t Mean Absolute Error:  %d\" %(n_estimators, my_mae))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_mae(n_estimators, train_X, val_X, train_y, val_y):\n    model = GradientBoostingRegressor(n_estimators=n_estimators,random_state=0,max_depth=3,max_leaf_nodes=5,\\\n                                      learning_rate=0.08) \n    model.fit(train_X, train_y)\n    preds_val = model.predict(val_X)\n    mae = mean_absolute_error(val_y, preds_val)\n    return(mae)\n\nfind_n_estimators = [500,505,510,515,520,525,530,535,540,545,550,555,560,565,570,575,580,585,590,595,600,\\\n                    605,610,615,620,625,630,635,640,645,650,655,660,665,670,675,680,685,690,695,700]\n# Write loop to find the ideal tree size from candidate_max_leaf_nodes\nfor n_estimators in find_n_estimators:\n    my_mae = get_mae(n_estimators, train_X, val_X, train_y, val_y)\n    print(\"n_estimators: %d  \\t\\t Mean Absolute Error:  %d\" %(n_estimators, my_mae))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_mae(n_estimators, train_X, val_X, train_y, val_y):\n    model = GradientBoostingRegressor(n_estimators=n_estimators,random_state=0,max_depth=3,\n                                      max_leaf_nodes=5,learning_rate=0.08) \n    model.fit(train_X, train_y)\n    preds_val = model.predict(val_X)\n    mae = mean_absolute_error(val_y, preds_val)\n    return(mae)\n\nfind_n_estimators = [700,705,710,715,720,725,730,735,740,745,750,755,760,765,770,775,780,785,790,\\\n                     795,800,805,810,815,820,825,830,835,840,845,850,855,860,865,870,875,880,885,\\\n                     890,895,900]\n# Write loop to find the ideal tree size from candidate_max_leaf_nodes\nfor n_estimators in find_n_estimators:\n    my_mae = get_mae(n_estimators, train_X, val_X, train_y, val_y)\n    print(\"n_estimators: %d  \\t\\t Mean Absolute Error:  %d\" %(n_estimators, my_mae))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_mae(n_estimators, train_X, val_X, train_y, val_y):\n    model = GradientBoostingRegressor(n_estimators=n_estimators,random_state=0,max_depth=3,\n                                      max_leaf_nodes=5,learning_rate=0.08) \n    model.fit(train_X, train_y)\n    preds_val = model.predict(val_X)\n    mae = mean_absolute_error(val_y, preds_val)\n    return(mae)\n\nfind_n_estimators = [900,905,910,915,920,925,930,935,940,945,950,955,960,965,970,975,980,985,990,\\\n                     995,1000,1005,1010,1015,1020,1025,1030,1035,1040,1045,1050,1055,1060,1065,\\\n                     1070,1075,1080,1085,\\\n                     1090,1095,1100]\n# Write loop to find the ideal tree size from candidate_max_leaf_nodes\nfor n_estimators in find_n_estimators:\n    my_mae = get_mae(n_estimators, train_X, val_X, train_y, val_y)\n    print(\"n_estimators: %d  \\t\\t Mean Absolute Error:  %d\" %(n_estimators, my_mae))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_mae(n_estimators, train_X, val_X, train_y, val_y):\n    model = GradientBoostingRegressor(n_estimators=n_estimators,random_state=0,max_depth=3,\n                                      max_leaf_nodes=5,learning_rate=0.08) \n    model.fit(train_X, train_y)\n    preds_val = model.predict(val_X)\n    mae = mean_absolute_error(val_y, preds_val)\n    return(mae)\n\nfind_n_estimators = [1100,1105,1110,1115,1120,1125,1130,1135,1140,1145,1150,1155,1160,1165,1170,\\\n                     1175,1180,1185,1190,\\\n                     1195,1200,1205,1210,1215,1220,1225,1230,1235,1240,1245,1250,1255,1260,1265,\\\n                     1270,1275,1280,1285,\\\n                     1290,1295,1200]\n# Write loop to find the ideal tree size from candidate_max_leaf_nodes\nfor n_estimators in find_n_estimators:\n    my_mae = get_mae(n_estimators, train_X, val_X, train_y, val_y)\n    print(\"n_estimators: %d  \\t\\t Mean Absolute Error:  %d\" %(n_estimators, my_mae))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_mae(n_estimators, train_X, val_X, train_y, val_y):\n    model = GradientBoostingRegressor(n_estimators=n_estimators,random_state=0,max_depth=3,\n                                      max_leaf_nodes=5,learning_rate=0.08) \n    model.fit(train_X, train_y)\n    preds_val = model.predict(val_X)\n    mae = mean_absolute_error(val_y, preds_val)\n    return(mae)\n\nfind_n_estimators = [1200,1205,1210,1215,1220,1225,1230,1235,1240,1245,1250,1255,1260,1265,1270,\\\n                     1275,1280,1285,1290,\\\n                     1295,1300,1305,1310,1315,1320,1325,1330,1335,1340,1345,1350,1355,1360,1365,\\\n                     1370,1375,1380,1385,\\\n                     1390,1395,1400]\n# Write loop to find the ideal tree size from candidate_max_leaf_nodes\nfor n_estimators in find_n_estimators:\n    my_mae = get_mae(n_estimators, train_X, val_X, train_y, val_y)\n    print(\"n_estimators: %d  \\t\\t Mean Absolute Error:  %d\" %(n_estimators, my_mae))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_mae(n_estimators, train_X, val_X, train_y, val_y):\n    model = GradientBoostingRegressor(n_estimators=n_estimators,random_state=0,max_depth=3,\n                                      max_leaf_nodes=5,learning_rate=0.08) \n    model.fit(train_X, train_y)\n    preds_val = model.predict(val_X)\n    mae = mean_absolute_error(val_y, preds_val)\n    return(mae)\n\nfind_n_estimators = [1300, 1400, 1500, 1600, 1700, 1800, 1900, 2000, 2100, 2200, 2300,2400,2500,2600,2700,2800,\n                     2900,3000]\n                    \n# Write loop to find the ideal tree size from candidate_max_leaf_nodes\nfor n_estimators in find_n_estimators:\n    my_mae = get_mae(n_estimators, train_X, val_X, train_y, val_y)\n    print(\"n_estimators: %d  \\t\\t Mean Absolute Error:  %d\" %(n_estimators, my_mae))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_mae(n_estimators, train_X, val_X, train_y, val_y):\n    model = GradientBoostingRegressor(n_estimators=n_estimators,random_state=0,max_depth=3,\n                                      max_leaf_nodes=5,learning_rate=0.08) \n    model.fit(train_X, train_y)\n    preds_val = model.predict(val_X)\n    mae = mean_absolute_error(val_y, preds_val)\n    return(mae)\n\nfind_n_estimators = [3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000, 11000, 12000, 13000,14000,15000,16000,17000,\n                     18000,1900,2000,30000]\n                    \n# Write loop to find the ideal tree size from candidate_max_leaf_nodes\nfor n_estimators in find_n_estimators:\n    my_mae = get_mae(n_estimators, train_X, val_X, train_y, val_y)\n    print(\"n_estimators: %d  \\t\\t Mean Absolute Error:  %d\" %(n_estimators, my_mae))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_model_on_full_data = GradientBoostingRegressor(random_state=0,max_leaf_nodes=5,n_estimators=625,\n                                              max_depth=3, learning_rate=0.08)\n\n# fit rf_model_on_full_data on all data from the training data\nrf_model_on_full_data.fit(X,y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Test Data\nRead the file of \"test\" data. And apply your model to make predictions"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"test_data_path = '../input/test.csv'\ntest_data = pd.read_csv(test_data_path)\n#test_data.head()\n#test_data['TotalBsmtSF'].unique()\n\ntest_data=test_data.rename(columns={'1stFlrSF':'FirstFlrSF', '2ndFlrSF' : 'SecondFlrSF'} )\n\ntest_data._get_numeric_data().head()"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reading the file\n\ntest_data_path = '../input/test.csv'\ntest_data = pd.read_csv(test_data_path)\n#test_data.head()\n#test_data['TotalBsmtSF'].unique()\n\n# Renaming Columns\n\ntest_data=test_data.rename(columns={'1stFlrSF':'FirstFlrSF', '2ndFlrSF' : 'SecondFlrSF'} )\n\n# Filling NAN values\n\ntest_data['SaleType']=test_data['SaleType'].fillna('WD')\ntest_data['PoolQC']=test_data['PoolQC'].fillna('Gd')\ntest_data['Fence']=test_data['Fence'].fillna('MnWw')\ntest_data['MiscFeature']=test_data['MiscFeature'].fillna('TenC')\ntest_data['GarageQual']=test_data['GarageQual'].fillna('Po')\ntest_data['GarageCond']=test_data['GarageCond'].fillna('Ex')\ntest_data['GarageArea']=test_data['GarageArea'].fillna(472.768861)\ntest_data['GarageCars']=test_data['GarageCars'].fillna(1.766118)\ntest_data['GarageYrBlt']=test_data['GarageYrBlt'].fillna(1978)\ntest_data['FireplaceQu']=test_data['FireplaceQu'].fillna('Po')\ntest_data['GarageType']=test_data['GarageType'].fillna('2Types')\ntest_data['GarageFinish']=test_data['GarageFinish'].fillna('Fin')\ntest_data['Functional']=test_data['Functional'].fillna('Min2') \ntest_data['KitchenQual']=test_data['KitchenQual'].fillna('TA')\ntest_data['BsmtFinSF1']=test_data['BsmtFinSF1'].fillna(439.203704)\ntest_data['BsmtFinSF2']=test_data['BsmtFinSF2'].fillna(52.619342)\ntest_data['TotalBsmtSF']=test_data['TotalBsmtSF'].fillna(1046.117970)\ntest_data['BsmtFullBath']=test_data['BsmtFullBath'].fillna( 0.434454)\ntest_data['BsmtHalfBath']=test_data['BsmtHalfBath'].fillna(0.065202)\ntest_data['LotFrontage']=test_data['LotFrontage'].fillna(70)\ntest_data['Alley']= test_data['Alley'].fillna('Pave')\ntest_data['Utilities']=test_data['Utilities'].fillna('AllPub')\ntest_data['Exterior1st']=test_data['Exterior1st'].fillna('CemntBd') \ntest_data['Exterior1st']=test_data['Exterior2nd'].fillna('HdBoard')\ntest_data['MasVnrType']=test_data['MasVnrType'].fillna('BrkCmn')\ntest_data['MasVnrArea']=test_data['MasVnrArea'].fillna(0)\ntest_data['BsmtQual']=test_data['BsmtQual'].fillna('Fa')\ntest_data['BsmtCond']=test_data['BsmtCond'].fillna('Po')\ntest_data['BsmtExposure']=test_data['BsmtExposure'].fillna('Av')\ntest_data['BsmtFinType1']=test_data['BsmtFinType1'].fillna('LwQ')\ntest_data['BsmtFinType2']=test_data['BsmtFinType2'].fillna('BLQ')\ntest_data['MSZoning']=test_data['MSZoning'].fillna('RH')\ntest_data['Exterior2nd']=test_data['Exterior2nd'].fillna('Plywood')\ntest_data['BsmtUnfSF']=test_data['BsmtUnfSF'].fillna(554.294925)\n\n#  Label Encoding\n\nfor f in ['MSZoning','Street', 'Alley', 'LotShape','LandContour','Utilities','LotConfig','LandSlope',\\\n          'Neighborhood','Condition1','Condition2','BldgType','HouseStyle',\\\n         'RoofStyle','RoofMatl','Exterior1st','Exterior2nd','MasVnrType','ExterQual','ExterCond',\\\n          'Foundation','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2',\\\n         'Heating','HeatingQC','CentralAir','Electrical','KitchenQual','Functional',\\\n          'FireplaceQu','GarageType','GarageFinish','GarageQual','GarageCond','PavedDrive',\\\n         'PoolQC','Fence','MiscFeature','SaleType','SaleCondition']:\n    lbl = LabelEncoder()\n    lbl.fit(list(test_data[f].values) + list(test_data[f].values))\n    #home_data[f] = lbl.transform(list(home_data[f].values))\n    test_data[f] = lbl.transform(list(test_data[f].values))\n    \n# Features\n\ntest_X=test_data[['MSZoning','Street', 'Alley', 'LotShape','LandContour','Utilities','LandSlope',\\\n         'Condition1','Condition2','BldgType','HouseStyle','LotConfig', 'Neighborhood',\\\n         'RoofStyle','RoofMatl','Exterior1st','Exterior2nd','ExterQual','ExterCond',\\\n          'BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2',\\\n         'Heating','HeatingQC','CentralAir','Electrical','KitchenQual','Functional',\\\n          'GarageType','GarageFinish','GarageQual','GarageCond','PavedDrive',\\\n         'PoolQC','Fence','MiscFeature','SaleType','SaleCondition','LotFrontage',\\\n             'BsmtFinSF2','BsmtFinSF1','LotArea', 'OverallQual','OverallCond','YearBuilt','YearRemodAdd','MasVnrArea',\\\n            'BsmtUnfSF','TotalBsmtSF','FirstFlrSF','SecondFlrSF','LowQualFinSF',\\\n             'BsmtFullBath','GrLivArea','BsmtHalfBath','FullBath','HalfBath','BedroomAbvGr',\\\n             'KitchenAbvGr','TotRmsAbvGrd','Fireplaces','GarageYrBlt','GarageCars','GarageArea',\\\n             'WoodDeckSF','OpenPorchSF','3SsnPorch','EnclosedPorch','ScreenPorch','PoolArea',\\\n             'MiscVal','MoSold','YrSold',\n           ]]\n                 \n\n\n# make predictions which we will submit. \ntest_preds = rf_model_on_full_data.predict(test_X)\n\n# The lines below shows how to save predictions in format used for competition scoring\n\noutput = pd.DataFrame({'Id': test_data.Id,'SalePrice': test_preds})\noutput.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"}},"nbformat":4,"nbformat_minor":1}
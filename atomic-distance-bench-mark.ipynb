{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# Now calculating length of a vector\n#train['length'] = train ['dist'] **2\n#test['length'] = test ['dist'] **2\n# XX, YY, 'ZZ'\ntrain['XX'] = train ['x_0'] * train ['x_1']\ntrain['YY'] = train ['y_0'] * train ['y_1']\ntrain['ZZ'] = train ['z_0'] * train ['z_1']\ntest['XX'] = test ['x_0'] * test ['x_1']\ntest['YY'] = test ['y_0'] * test ['y_1']\ntest['ZZ'] = test ['z_0'] * test ['z_1']\n\n\n# XY, XZ, \ntrain['XY'] = train ['x_0'] * train ['y_1']\ntrain['XZ'] = train ['x_0'] * train ['z_1']\ntest['XY'] = test ['x_0'] * test ['y_1']\ntest['XZ'] = test ['x_0'] * test ['z_1']\n\n\n# YX, 'YZ'\ntrain['YX'] = train ['y_0'] * train ['x_1']\ntrain['YZ'] = train ['y_0'] * train ['z_1']\ntest['YX'] = test ['y_0'] * test ['x_1']\ntest['YZ'] = test ['y_0'] * test ['z_1']\n\n# ZX, ZY\ntrain['ZX'] = train ['z_0'] * train ['x_1']\ntrain['ZY'] = train ['z_0'] * train ['y_1']\ntest['ZX'] = test ['z_0'] * test ['x_1']\ntest['ZY'] = test ['z_0'] * test ['y_1']\n\n\n# make categorical variables\natom_map = {'H': 0,\n            'C': 1,\n            'N': 2,\n            'O':4}\ntrain['atom_0_cat'] = train['atom_0'].map(atom_map).astype('int')\ntrain['atom_1_cat'] = train['atom_1'].map(atom_map).astype('int')\ntest['atom_0_cat'] = test['atom_0'].map(atom_map).astype('int')\ntest['atom_1_cat'] = test['atom_1'].map(atom_map).astype('int')\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\n\n# import warnings filter\nfrom warnings import simplefilter\n# ignore all future warnings\nsimplefilter(action='ignore', category=FutureWarning)\n\nimport os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GroupKFold\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.ensemble import RandomForestRegressor\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/train.csv', index_col='id')\ntest = pd.read_csv('../input/test.csv', index_col='id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(train.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['atom_index_1'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print (test.dtypes)\n#print (test.shape)\ndisplay(test.head(10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ms = pd.read_csv('../input/magnetic_shielding_tensors.csv')\nms.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"structures = pd.read_csv('../input/structures.csv')\ndisplay(structures.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"structures.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pe = pd.read_csv('../input/potential_energy.csv')\ndisplay(pe.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pe.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#scalar_coupling_contribution = pd.read_csv('../input/scalar_coupling_contributions.csv')\n#display(scalar_coupling_contribution.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Map the atom structure data into train and test files\n\ndef map_atom_info(df, atom_idx):\n    df = pd.merge(df, structures, how = 'left',\n                  left_on  = ['molecule_name', f'atom_index_{atom_idx}'],\n                  right_on = ['molecule_name',  'atom_index'])\n    \n    df = df.drop('atom_index', axis=1)\n    df = df.rename(columns={'atom': f'atom_{atom_idx}',\n                            'x': f'x_{atom_idx}',\n                            'y': f'y_{atom_idx}',\n                            'z': f'z_{atom_idx}'})\n    return df\n\ntrain = map_atom_info(train, 0)\ntrain = map_atom_info(train, 1)\n\ntest = map_atom_info(test, 0)\ntest = map_atom_info(test, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Engineer a single feature: distance vector between atoms\n#  (there's ways to speed this up!)\n\ndef dist(row):\n    return ( (row['x_1'] - row['x_0'])**2 +\n             (row['y_1'] - row['y_0'])**2 +\n             (row['z_1'] - row['z_0'])**2 ) ** 0.5\n\ntrain['dist'] = train.apply(lambda x: dist(x), axis=1)\ntest['dist'] = test.apply(lambda x: dist(x), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# make categorical variables\natom_map = {'H': 0,\n            'C': 1,\n            'N': 2,\n            'O':4}\ntrain['atom_0_cat'] = train['atom_0'].map(atom_map).astype('int')\ntrain['atom_1_cat'] = train['atom_1'].map(atom_map).astype('int')\ntest['atom_0_cat'] = test['atom_0'].map(atom_map).astype('int')\ntest['atom_1_cat'] = test['atom_1'].map(atom_map).astype('int')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type_map = {'1JHC': 0,\n            '2JHH': 1,\n            '1JHN': 2,\n            '2JHN':3,\n           '2JHN':4,\n           '2JHC':5,\n           '3JHH':6,\n           '3JHC':7,\n           '3JHN':8}\n\ntrain['type_cat'] = train['type'].map(type_map).astype('int')\ntest['type_cat'] = test['type'].map(type_map).astype('int')\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = train.pop('scalar_coupling_constant')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X=train.drop(['molecule_name','type','atom_0','atom_1'] ,axis=1)\nX.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeRegressor\n\n#y = train.pop('scalar_coupling_constant')\n#X = train.drop('molecule_name',axis=1)\n\n# Split into validation and training data\ntrain_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\n\ndef get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y):\n    model = RandomForestRegressor(max_leaf_nodes=max_leaf_nodes, random_state=1)\n    model.fit(train_X, train_y)\n    preds_val = model.predict(val_X)\n    mae = mean_absolute_error(val_y, preds_val)\n    return(mae)\n\ncandidate_max_leaf_nodes = [5,10,15,20, 25]# 50,75, 100,125,150,175,200, 250, 500]\n# Write loop to find the ideal tree size from candidate_max_leaf_nodes\nfor max_leaf_nodes in candidate_max_leaf_nodes:\n    my_mae = get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y)\n    print(\"Max leaf nodes: %d  \\t\\t Mean Absolute Error:  %d\" %(max_leaf_nodes, my_mae))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_mae(n_estimators, train_X, val_X, train_y, val_y):\n    model = RandomForestRegressor(n_estimators=n_estimators, random_state=1,n_jobs=-1)\n    model.fit(train_X, train_y)\n    preds_val = model.predict(val_X)\n    mae = mean_absolute_error(val_y, preds_val)\n    return(mae)\n\nfind_n_estimators = [5, 25, 50,75, 100]#,125,150,175,200, 250, 500]\n# Write loop to find the ideal tree size from find_n_estimators\nfor n_estimators in find_n_estimators:\n    my_mae = get_mae(n_estimators, train_X, val_X, train_y, val_y)\n    print(\"n_estimators: %d  \\t\\t Mean Absolute Error:  %d\" %(n_estimators, my_mae))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"molecules = train.pop('molecule_name')\ntest = test.drop('molecule_name', axis=1)\n\ny = train.pop('scalar_coupling_constant')\n\n# Label Encoding\nfor f in ['type', 'atom_0', 'atom_1']:\n    lbl = LabelEncoder()\n    lbl.fit(list(train[f].values) + list(train[f].values))\n    train[f] = lbl.transform(list(train[f].values))\n    test[f] = lbl.transform(list(test[f].values))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"yoof = np.zeros(len(train))\nyhat = np.zeros(len(test))\n\nn_splits = 3\ngkf = GroupKFold(n_splits=n_splits) # we're going to split folds by molecules\n\nfold = 0\nfor in_index, oof_index in gkf.split(train, y, groups=molecules):\n    fold += 1\n    print(f'fold {fold} of {n_splits}')\n    X_in, X_oof = train.values[in_index], train.values[oof_index]\n    y_in, y_oof = y.values[in_index], y.values[oof_index]\n    reg = RandomForestRegressor(n_estimators=10,\n                                max_depth=None,\n                                min_samples_leaf=3,\n                                n_jobs=-1)\n    reg.fit(X_in, y_in)\n    yoof[oof_index] = reg.predict(X_oof)\n    yhat += reg.predict(test)\n\nyhat /= n_splits","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission = pd.read_csv('../input/sample_submission.csv', index_col='id')\n\nbenchmark = sample_submission.copy()\nbenchmark['scalar_coupling_constant'] = yhat\nbenchmark.to_csv('atomic_distance_benchmark.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_data = pd.DataFrame(y)\nplot_data.index.name = 'id'\nplot_data['yhat'] = yoof\nplot_data['type'] = pd.read_csv('../input/train.csv', index_col='id', usecols=['id', 'type'])\n\ndef plot_oof_preds(ctype, llim, ulim):\n        plt.figure(figsize=(6,6))\n        sns.scatterplot(x='scalar_coupling_constant',y='yhat',\n                        data=plot_data.loc[plot_data['type']==ctype,\n                        ['scalar_coupling_constant', 'yhat']]);\n        plt.xlim((llim, ulim))\n        plt.ylim((llim, ulim))\n        plt.plot([llim, ulim], [llim, ulim])\n        plt.xlabel('scalar_coupling_constant')\n        plt.ylabel('predicted')\n        plt.title(f'{ctype}', fontsize=18)\n        plt.show()\n\nplot_oof_preds('1JHC', 0, 250)\nplot_oof_preds('1JHN', 0, 100)\nplot_oof_preds('2JHC', -50, 50)\nplot_oof_preds('2JHH', -50, 50)\nplot_oof_preds('2JHN', -25, 25)\nplot_oof_preds('3JHC', -25, 100)\nplot_oof_preds('3JHH', -20, 20)\nplot_oof_preds('3JHN', -15, 15)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}
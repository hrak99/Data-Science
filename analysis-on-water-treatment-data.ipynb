{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Maximazing the Dsiplay\npd.set_option('display.max_columns', None) \npd.set_option('display.max_rows', None)\npd.set_option('display.width', None)\n\nfrom warnings import simplefilter\n# ignore all future warnings\nsimplefilter(action='ignore', category=FutureWarning)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"water_treatment= pd.read_excel('/kaggle/input/water_treatment.xlsx',header=None)\nwater_treatment.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# PREPROCESSING"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Droping unneccessary columns\nwater_treatment= water_treatment.drop([0],axis=1)\nprint ('Number of columns and rows',water_treatment.shape)\nprint ('Type of each column',water_treatment.dtypes)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Missing Values"},{"metadata":{},"cell_type":"markdown","source":"### There are many ways to handle missing values. \n### 1. Delete the whole row containing any missing or null values like here '?'. In this case you can loss the data\n\n### 2. Replacing all the missing or null values with any number like 0, max,min, std, mean of that feature, or any muneric value according to situation.\n\n### In our case, we will take mean or average value of the feature. It would be inappropriate to take '0' as a value because most of the cell contain some data. It also can't be certain that this value will be a perfect data of that position but it will assist to go with the approximately value. \n\n### As most of the columns are showing in object form, so we first replace '?' by 0. After that, we will convert all the columns into float. Now we will replace '0' by mean of every feature or column.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# replacing '?' by 0\nwater_treatment=water_treatment.replace('?', 0)\n# Converting all in to float\nwater_treatment = water_treatment.apply(lambda x: x.astype(np.float64), axis=1)\n# Now we can have all the relevant statistics of each column\nwater_treatment.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Replacing '0' of each column with average value\nwater_treatment=water_treatment.replace(0.0,water_treatment.mean())\nwater_treatment.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Normalization"},{"metadata":{},"cell_type":"markdown","source":"### Normalization usually means to scale a variable to have a values between 0 and 1"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing\nnormalizing_data = water_treatment.values #returns a numpy array\nmin_max_scaler = preprocessing.MinMaxScaler()\nnormalized_data = min_max_scaler.fit_transform(normalizing_data)\nwater_treatment_normalized = pd.DataFrame(normalized_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Normalize Data\nwater_treatment_normalized.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# K-MEANS CLUSTERING"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.cluster import KMeans \nclusterNum = 3\nk_means = KMeans(init = \"k-means++\", n_clusters = clusterNum, n_init = 12)\nk_means.fit(water_treatment_normalized)\nlabels = k_means.labels_\nprint(labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"water_treatment[\"Cluster\"] = labels\nwater_treatment.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output= water_treatment[[\"Cluster\"]]\noutput.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output.to_csv(r'kmean.txt', sep='\\t')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X=water_treatment.ix[:,0:38].values\ny = water_treatment['Cluster'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=4)\nprint ('Train set:', X_train.shape,  y_train.shape)\nprint ('Test set:', X_test.shape,  y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nk = 3\n#Train Model and Predict  \nneigh = KNeighborsClassifier(n_neighbors = k).fit(X_train,y_train)\nneigh","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"yhat = neigh.predict(X_test)\n#yhat[0:5]\nfrom sklearn import metrics\nprint(\"Train set Accuracy: \", metrics.accuracy_score(y_train, neigh.predict(X_train)))\nprint(\"Test set Accuracy: \", metrics.accuracy_score(y_test, yhat))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Ks = 10\nmean_acc = np.zeros((Ks-1))\nstd_acc = np.zeros((Ks-1))\nConfustionMx = [];\nfor n in range(1,Ks):\n    \n    #Train Model and Predict  \n    neigh = KNeighborsClassifier(n_neighbors = n).fit(X_train,y_train)\n    yhat=neigh.predict(X_test)\n    mean_acc[n-1] = metrics.accuracy_score(y_test, yhat)\n\n    \n    std_acc[n-1]=np.std(yhat==y_test)/np.sqrt(yhat.shape[0])\n\nmean_acc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(range(1,Ks),mean_acc,'g')\nplt.fill_between(range(1,Ks),mean_acc - 1 * std_acc,mean_acc + 1 * std_acc, alpha=0.10)\nplt.legend(('Accuracy ', '+/- 3xstd'))\nplt.ylabel('Accuracy ')\nplt.xlabel('Number of Nabors (K)')\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print( \"The best accuracy was with\", mean_acc.max(), \"with k=\", mean_acc.argmax()+1) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# PCA"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nx=water_treatment.ix[:,0:38].values\ny =water_treatment['Cluster'].values\n# Standardizing the features\nx = StandardScaler().fit_transform(x)\nfrom sklearn.decomposition import PCA\npca = PCA(n_components=2)\nprincipalComponents = pca.fit_transform(x)\nprincipalDf = pd.DataFrame(data = principalComponents, columns = ['principal component 1', 'principal component 2'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"principalDf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"normalizing_data = principalDf.values #returns a numpy array\nmin_max_scaler = preprocessing.MinMaxScaler()\nnormalized_data = min_max_scaler.fit_transform(normalizing_data)\nprincipalDf_normalized = pd.DataFrame(normalized_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"principalDf_normalized.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clusterNum = 3\nk_means = KMeans(init = \"k-means++\", n_clusters = clusterNum, n_init = 12)\nk_means.fit(principalDf_normalized)\nlabels = k_means.labels_\nprint(labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"principalDf[\"Cluster\"] = labels\nprincipalDf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = principalDf.ix[:,0:2].values\ny = principalDf['Cluster'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=4)\nprint ('Train set:', X_train.shape,  y_train.shape)\nprint ('Test set:', X_test.shape,  y_test.shape)\nfrom sklearn.neighbors import KNeighborsClassifier\nk = 4\n#Train Model and Predict  \nneigh = KNeighborsClassifier(n_neighbors = k).fit(X_train,y_train)\nneigh\nyhat = neigh.predict(X_test)\nyhat[0:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\nprint(\"Train set Accuracy: \", metrics.accuracy_score(y_train, neigh.predict(X_train)))\nprint(\"Test set Accuracy: \", metrics.accuracy_score(y_test, yhat))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Ks = 10\nmean_acc = np.zeros((Ks-1))\nstd_acc = np.zeros((Ks-1))\nConfustionMx = [];\nfor n in range(1,Ks):\n    \n    #Train Model and Predict  \n    neigh = KNeighborsClassifier(n_neighbors = n).fit(X_train,y_train)\n    yhat=neigh.predict(X_test)\n    mean_acc[n-1] = metrics.accuracy_score(y_test, yhat)\n\n    \n    std_acc[n-1]=np.std(yhat==y_test)/np.sqrt(yhat.shape[0])\n\nmean_acc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(range(1,Ks),mean_acc,'g')\nplt.fill_between(range(1,Ks),mean_acc - 1 * std_acc,mean_acc + 1 * std_acc, alpha=0.10)\nplt.legend(('Accuracy ', '+/- 3xstd'))\nplt.ylabel('Accuracy ')\nplt.xlabel('Number of Nabors (K)')\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print( \"The best accuracy was with\", mean_acc.max(), \"with k=\", mean_acc.argmax()+1) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## For k=1, PCA"},{"metadata":{"trusted":true},"cell_type":"code","source":"clusterNum = 1\nk_means = KMeans(init = \"k-means++\", n_clusters = clusterNum, n_init = 12)\nk_means.fit(principalDf_normalized)\nlabels = k_means.labels_\nprint(labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"principalDf[\"Cluster\"] = labels\nprincipalDf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output= principalDf[['Cluster']]\noutput.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output.to_csv(r'kmean_PCA.txt', sep='\\t')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Autoencoder"},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Input, Dense\nfrom keras.models import Model\nfrom keras.optimizers import adam,sgd\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X=water_treatment.ix[:,0:38].values\nY = water_treatment['Cluster'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"min_max_scaler = preprocessing.MinMaxScaler()\nX = min_max_scaler.fit_transform(X)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# seed for reproducing same results\nseed = 20\nnp.random.seed(seed)\n\n# split the data into training (80%) and testing (20%)\n(x_train, x_test, y_train, y_test) = train_test_split(X, Y, test_size=0.20, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# reduce to 2 features\nencoding_dim = 2\n\ninput_df = Input(shape=(38,))\nencoded = Dense(encoding_dim, activation='relu')(input_df)\ndecoded = Dense(38, activation='sigmoid')(encoded)\n\n# encoder\nautoencoder = Model(input_df, decoded)\n\n# intermediate result\nencoder = Model(input_df, encoded)\n\nautoencoder.compile(optimizer='adadelta', loss='MAE',metrics=['accuracy']) # adadelta\n\nhistory=autoencoder.fit(x_train, x_train,\n                epochs=100,\n                batch_size=512,\n                shuffle=True,\n                validation_data=(x_test, x_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n# list all data in history\nprint(history.history.keys())\n# summarize history for accuracy\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#np.savetxt(r's.txt', output.values, fmt='%d',delimiter=\"\\t\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#np.savetxt('xgboost.txt', output.values, fmt='%d', delimiter=\"\\t\", header=None)  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#np.savetxt('a.txt', output.values, fmt='%d')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}